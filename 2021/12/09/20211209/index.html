<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>爬虫专题01 | 聂泽宇的blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="一点关于小小爬虫（读者需要对基本的浏览器操作，python用法和电脑知识有所了解）首先我们想到如果，一个东西可以在网页上被我们看见，那么他必然将对应的数据包传输到了我的电脑上，那么我就可以直接拿下数据包，直接获取数据。 首先我们需要一个requests包，进行request请求 首先举个例子，我们如何爬取百度的首页，第一步我们需要得到百度的url即”https:&#x2F;&#x2F;www.baidu.com&amp;qu">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫专题01">
<meta property="og:url" content="http://example.com/2021/12/09/20211209/index.html">
<meta property="og:site_name" content="聂泽宇的blog">
<meta property="og:description" content="一点关于小小爬虫（读者需要对基本的浏览器操作，python用法和电脑知识有所了解）首先我们想到如果，一个东西可以在网页上被我们看见，那么他必然将对应的数据包传输到了我的电脑上，那么我就可以直接拿下数据包，直接获取数据。 首先我们需要一个requests包，进行request请求 首先举个例子，我们如何爬取百度的首页，第一步我们需要得到百度的url即”https:&#x2F;&#x2F;www.baidu.com&amp;qu">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-12-09T03:09:42.000Z">
<meta property="article:modified_time" content="2021-12-09T03:15:34.190Z">
<meta property="article:author" content="聂泽宇">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="聂泽宇的blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">聂泽宇的blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">--开局一张嘴，故事全靠编</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-20211209" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/12/09/20211209/" class="article-date">
  <time class="dt-published" datetime="2021-12-09T03:09:42.000Z" itemprop="datePublished">2021-12-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      爬虫专题01
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一点关于小小爬虫"><a href="#一点关于小小爬虫" class="headerlink" title="一点关于小小爬虫"></a>一点关于小小爬虫</h2><p>（读者需要对基本的浏览器操作，python用法和电脑知识有所了解）<br>首先我们想到如果，一个东西可以在网页上被我们看见，那么他必然将对应的数据包传输到了我的电脑上，那么我就可以直接拿下数据包，直接获取数据。</p>
<p>首先我们需要一个requests包，进行request请求</p>
<p>首先举个例子，我们如何爬取百度的首页，第一步我们需要得到百度的url即”<a target="_blank" rel="noopener" href="https://www.baidu.com&quot;,http代表ipv4,https代表ipv6,由于我们是爬虫访问,不是浏览器访问,所以说并不会自动补全http和https,所以说必须加上.第二步,百度对检测访问者的身份,所以说,我们需要自己手动加上请求头用户代理,一般来说可以用自己的真实ip,也可以导包“fake_useragent”与“random”./">https://www.baidu.com&quot;，http代表ipv4，https代表ipv6，由于我们是爬虫访问，不是浏览器访问，所以说并不会自动补全http和https，所以说必须加上。第二步，百度对检测访问者的身份，所以说，我们需要自己手动加上请求头用户代理，一般来说可以用自己的真实ip，也可以导包“fake_useragent”与“random”。</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> FakeUserAgent</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># headers_=&#123;&quot;User-Agent&quot;:FakeUserAgent().random&#125;</span></span><br><span class="line">    headers_=&#123;<span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    url_1=<span class="string">&quot;https://www.baidu.com&quot;</span></span><br><span class="line">    response=requests.get(url_1,headers=headers_,)</span><br><span class="line">    response.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(response.content)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;baidu.html&quot;</span>,<span class="string">&quot;w&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.text)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果读者以及看懂了网页案例，那么我们不妨升级，我想要获得百度搜索的结果的网页，对url进行分析，那么不难得到它其中有一个wd参数，我们只需要一个params参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> FakeUserAgent</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># headers_=&#123;&quot;User-Agent&quot;:FakeUserAgent().random&#125;</span></span><br><span class="line">    headers_=&#123;<span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    url_1=<span class="string">&quot;https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=1&amp;tn=baidu&quot;</span></span><br><span class="line">    params_=&#123;<span class="string">&quot;wd&quot;</span>:<span class="string">&quot;电磁炮&quot;</span>&#125;</span><br><span class="line">    response=requests.get(url_1,headers=headers_,params=params_)</span><br><span class="line">    response.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(response.content)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;baidu.html&quot;</span>,<span class="string">&quot;w&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>接着向下，如果我想要得到某张图片某个视频某个音频，那么我们需要对数据包进行分析，得到图片的url，如何将其爬取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    url_=<span class="string">&quot;&quot;</span></span><br><span class="line">    headers_=&#123;<span class="string">&quot;&#x27;&#125;</span></span><br><span class="line"><span class="string">    res_=requests.get(url_,headers=headers_)</span></span><br><span class="line"><span class="string">    with open(&quot;</span>.mp4/jpg/...<span class="string">&quot;,&quot;</span>w<span class="string">b&quot;) as f:</span></span><br><span class="line"><span class="string">        f.write(res_.content)</span></span><br></pre></td></tr></table></figure>
<p>由此我们可以思考的，我既然可以在网上听歌，那么我是不是也可以爬取网易云或者是什么音乐播放器的会员音频呢，因为这种音乐我们不开VIP是不能直接听的，所以说我们不难直接爬取音频文件，但是通过观察，我们可以看它的mv，那么我们思考到，我们为什么不从mv中提取音乐呢<br>可以自己尝试，这里不加赘述。</p>
<p>那么我们由此联想到，我们可以爬取bilibili里面的视频呢，通过分析数据包，和初步的爬取，我们发现bilibili是将音频和视频分开的，那么我们需要将其合成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> moviepy.editor <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    url_=<span class="string">&quot;&quot;</span></span><br><span class="line">    headers_=&#123;<span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    res_=requests.get(url_,headers=headers_)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;.mp4&quot;</span>,<span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(res_.content)</span><br><span class="line">    url_=<span class="string">&quot;&quot;</span></span><br><span class="line">    res_=requests.get(url_,headers=headers_)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;.acc&quot;</span>,<span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    	f.write(res_.content)</span><br><span class="line">    os.system(<span class="string">&#x27;C:\/Users\lenovo\Desktop\代码\python\/ffmpeg-N-102852-g758e2da289-win64-gpl-shared\/bin\/ffmpeg.exe -i &quot;.mp4&quot; -i &quot;.aac&quot; -c:v copy -c:a copy -bsf:a aac_adtstoasc .mp4 -loglevel quiet&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功&quot;</span>)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/12/09/20211209/" data-id="ckwydwe7h0000v0uj9pv40umi" data-title="爬虫专题01" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/12/07/20211207/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">20211207</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%9B%E4%B8%96%E7%BA%AA%E5%85%83/" rel="tag">创世纪元</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E5%88%9B%E4%B8%96%E7%BA%AA%E5%85%83/" style="font-size: 10px;">创世纪元</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/12/09/20211209/">爬虫专题01</a>
          </li>
        
          <li>
            <a href="/2021/12/07/20211207/">20211207</a>
          </li>
        
          <li>
            <a href="/2021/12/07/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 聂泽宇<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>